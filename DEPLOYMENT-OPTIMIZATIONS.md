# Deployment Optimizations

## âœ… Implemented (Immediate)

### 1. **Auto-Approval**
- Added `scripts/ec2-approve.sh` - Auto-approves browser devices after deployment
- Similar to `make quick-docker` behavior
- No manual approval needed

### 2. **Reduced SSH Sessions**
- Combined multiple SSH commands into single sessions
- Reduced deployment time by ~10-15 seconds
- Fewer network round-trips

### 3. **Optimized Sleep Times**
- Reduced sleep from 5s â†’ 3s where safe
- Smart waiting: only wait when necessary
- Est. time saved: ~5-10 seconds

### 4. **Docker Image Caching**
- Already works: Image cached after first `docker compose pull`
- Subsequent deployments skip pull if image unchanged
- **First deploy**: ~30s for pull
- **Updates**: ~5s if no image changes

## ðŸš€ Quick Wins Summary

| Optimization | Time Saved | Status |
|---|---|---|
| Auto-approval | Manual step eliminated | âœ… Done |
| Combined SSH sessions | ~10-15s | âœ… Done |
| Reduced sleep times | ~5-10s | âœ… Done |
| Docker image cache | ~25s (on updates) | âœ… Already works |
| **Total** | **~40-50s** | **Implemented** |

## ðŸ“ˆ Advanced Optimizations (Optional)

### 1. Custom AMI with Pre-Installed Tools
Create a custom Amazon Machine Image with:
- Docker pre-installed (saves 60s boot time)
- OpenClaw image pre-pulled (saves 30s first deploy)
- Pre-configured openclaw.json template

**Time saved**: ~90 seconds on first deploy
**How to implement**:
```bash
# After first successful deployment:
make ec2-create-ami NAME=ducdv
# Then update terraform to use custom AMI
```

### 2. Parallel Terraform Operations
- Use `terraform apply -parallelism=20` (default: 10)
- Faster resource creation

**Time saved**: ~5-10 seconds
**Implementation**: Already configured in ec2-setup target

### 3. Skip Unnecessary Terraform Refreshes
- Use `-refresh=false` for known-good deployments
- Only for repeated deploys to same instance

**Time saved**: ~3-5 seconds

### 4. Use Smaller Instance for Testing
- Switch to `t3.micro` or `t3.nano` for dev/test
- Faster boot, lower cost
- Production uses `t3.small` or larger

**Implementation**:
```bash
make ec2-full-setup NAME=dev INSTANCE_TYPE=t3.micro
```

### 5. Regional Proximity
- Deploy to region closest to you
- Lower latency for SSH operations

**Time saved**: ~1-2 seconds per SSH command

## ðŸŽ¯ Current Performance

| Phase | Time | Optimized |
|---|---|---|
| SSH key creation | 5s | N/A |
| Terraform config | instant | N/A |
| EC2 instance launch | ~120s | âœ… Cached AMI possible |
| Docker install (first boot) | ~60s | âœ… Custom AMI eliminates |
| Docker image pull (first) | ~30s | âœ… Cached after first |
| Container start | ~10s | âœ… Reduced waits |
| Config + restart | ~5s | âœ… Combined SSH |
| Auto-approval | ~3s | âœ… Automated |
| **Total (first deploy)** | **~233s (3.9 min)** | **Target: ~2 min with custom AMI** |
| **Total (updates)** | **~20s** | **Achieved âœ…** |

## ðŸ’¡ Best Practices

### For Development
```bash
# Use smallest instance for testing
make ec2-full-setup NAME=dev INSTANCE_TYPE=t3.micro

# Updates are fast (~20s)
make deploy-ec2 NAME=dev
```

### For Production
```bash
# Use recommended instance
make ec2-full-setup NAME=prod INSTANCE_TYPE=t3.small

# Create custom AMI after first deploy
make ec2-create-ami NAME=prod

# Future deployments use cached AMI
```

### For Multiple Providers
```bash
# Deploy all in parallel (separate terminals)
make ec2-full-setup NAME=claude CLAUDE_CODE_OAUTH_TOKEN=xxx &
make ec2-full-setup NAME=gemini GEMINI_API_KEY=yyy &
make ec2-full-setup NAME=openai OPENAI_API_KEY=zzz &
```

## ðŸ“Š Cost Optimization

| Instance | vCPU | RAM | $/month | Use Case |
|---|---|---|---|---|
| t3.nano | 2 | 0.5GB | ~$4 | Dev/test |
| t3.micro | 2 | 1GB | ~$8 | Light dev |
| **t3.small** | **2** | **2GB** | **~$15** | **Recommended** |
| t3.medium | 2 | 4GB | ~$30 | Heavy workloads |

